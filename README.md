# url_shortener

<!--toc:start-->
- [url_shortener](#urlshortener)
  - [Stack](#stack)
  - [Stress test results](#stress-test-results)
    - [V1. Use auto-increment key](#v1-use-auto-increment-key)
      - [POST](#post)
      - [GET](#get)
  - [Thoughts](#thoughts)
<!--toc:end-->

a simple url shortener service written in Go

## Stack

- web framework: `Fiber`
- DB: `PostgreSQL`
- DB toolchain: `migrate`, `sqlc`
- Container/Orchestration: Docker/Docker compose
- stress test: `wrk`

## Stress test results

### V1. Use auto-increment key

The version V1 implements the basic functionalities of a url shortener. I used
the database's auto-incremented primary key as the slug, with the base62
format.

The string is not "random" at all, but after some queries, we could have
something like `http://localhost:3000/2AW9` that can satisfy the need.

I tested the parts that could easily go wrong during the dev, that is the
POST handler validation part and the base62 encoder and decoder. For the rest
of the code, it doesn't have a lot of logic, so a manual test is sufficient.

I added `wrk` script to run the stress test which by the way verified the
validation of 2 handlers.

The SQL commands generated by `sqlc` can be tested separately so that we can
create a mock for `sqlc` generated code for integration tests without the
real DB connection.

#### POST

3000 - 3500 QPS

```bash
<@url_shortener>-<⎇ main>-> wrk -t2 -d30s -c10 -s ./scripts/wrk/shorten.lua http://localhost:3000/
Running 30s test @ http://localhost:3000/
  2 threads and 10 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.17ms    1.17ms  16.14ms   61.95%
    Req/Sec     1.59k   584.07     3.24k    80.83%
  95024 requests in 30.01s, 12.96MB read
Requests/sec:   3166.17
Transfer/sec:    442.15KB
<@url_shortener>-<⎇ main>-<±>-> wrk -t2 -d30s -c10 -s ./scripts/wrk/shorten.lua http://localhost:3000/
Running 30s test @ http://localhost:3000/
  2 threads and 10 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.81ms    1.14ms  12.12ms   66.73%
    Req/Sec     1.79k   663.18     3.16k    70.00%
  106860 requests in 30.01s, 14.57MB read
Requests/sec:   3561.01
Transfer/sec:    497.29KB
```

![profile_post_v1](./docs/profile_post_v1.png)


#### GET

16000 - 20000 QPS (**Before adding the count**)

```bash
<@url_shortener>-<⎇ main>-<±>-> wrk -t2 -d30s -c10 -s ./scripts/wrk/get.lua http://localhost:3000/2AW9
Running 30s test @ http://localhost:3000/2AW9
  2 threads and 10 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.37ms    6.41ms 131.83ms   97.51%
    Req/Sec     8.18k     2.96k   11.78k    65.33%
  488349 requests in 30.00s, 50.30MB read
Requests/sec:  16276.73
Transfer/sec:      1.68MB
```


![profile_get_v1](./docs/profile_get_v1.png)

**700 QPS** after changing from a get to update

```bash
<@url_shortener>-<⎇ main>-> wrk -t2 -d30s -c10 -s ./scripts/wrk/get.lua http://localhost:3000/ABC
Running 30s test @ http://localhost:3000/ABC
  2 threads and 10 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    15.24ms   11.37ms 131.12ms   82.83%
    Req/Sec   361.55     44.87   490.00     71.17%
  21608 requests in 30.02s, 2.35MB read
Requests/sec:    719.82
Transfer/sec:     80.14KB
```

## Thoughts

- I chose `Fiber` and `sqlc` because in another showcase project `secumon` I have
used `Gin` and `Gorm`. It is to show that I can adapt with different tools
based on the existent project setup.
- At `dao` level, I have directly put the generated code. The advantage is that
we have reduced a level of abstraction that "does nothing". But the
inconvenience is that in `repo` level, we depend on `pgConn.pgError` that has
to be changed if we change to another middleware like `GORM`. But it is
acceptable for the sake of simplicity.
